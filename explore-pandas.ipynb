{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3c25f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f7fc2e",
   "metadata": {},
   "source": [
    "### Download sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86fdf87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# download sample dataset\n",
    "\n",
    "download_url = \"https://raw.githubusercontent.com/fivethirtyeight/data/master/nba-elo/nbaallelo.csv\"\n",
    "target_csv_path = \"nba_all_elo.csv\"\n",
    "\n",
    "response = requests.get(download_url)\n",
    "response.raise_for_status()\n",
    "\n",
    "with open(target_csv_path, \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "print(\"Downloaded dataset successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b24bc2",
   "metadata": {},
   "source": [
    "### Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e314bc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore dataset using pandas\n",
    "\n",
    "nba = pd.read_csv(\"nba_all_elo.csv\")\n",
    "print(\"type is: \", type(nba))\n",
    "print(\"number of rows are: \",len(nba))\n",
    "print(\"shape of df is: \",nba.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5453d59a",
   "metadata": {},
   "source": [
    "### Getting to know dataset and get basic statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049206ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display first or last 5 rows of df\n",
    "pd.set_option(\"display.max.columns\", None)\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "nba.head() # custom number of rows nb.head(3)\n",
    "# nba.tail() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe41626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data types and other info of the columns.\n",
    "nba.info()\n",
    "\n",
    "\n",
    "# pandas uses the numpy library to work with its datatypes \n",
    "# and also there other complex categorical data types which\n",
    "# are implemented by pandas python library itself.\n",
    "\n",
    "\n",
    "\n",
    "# The object data type is a special one. \n",
    "# According to the Pandas Cookbook, \n",
    "# the object data type is “a catch-all for columns that Pandas doesn’t recognize as any other specific type.” \n",
    "# In practice, it often means that all of the values in the column are strings.\n",
    "\n",
    "\n",
    "# Although you can store arbitrary Python objects in the object data type, \n",
    "# you should be aware of the drawbacks to doing so. \n",
    "# Strange values in an object column can harm Pandas’ performance and its interoperability with other libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0675be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get basic statistics\n",
    "nba.describe() \n",
    "# This function shows some basic descriptive statistics for all numeric columns.\n",
    "\n",
    "\n",
    "# .describe() only analyzes numeric columns by default, but you can provide other \n",
    "# data types if you use the include parameter\n",
    "\n",
    "\n",
    "# nba.describe(include=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67f09ae",
   "metadata": {},
   "source": [
    "### Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f3d8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring dataset\n",
    "# Exploratory data analysis can help you answer questions about dataset.\n",
    "\n",
    "# example:\n",
    "\n",
    "# how often specific values occur in a column\n",
    "\n",
    "# print(nba[\"team_id\"].value_counts())\n",
    "# print(nba[\"fran_id\"].value_counts())\n",
    "# print(nba.loc[nba[\"fran_id\"] == \"Lakers\", \"team_id\"].value_counts())\n",
    "\n",
    "# nba[\"date_played\"] = pd.to_datetime(nba[\"date_game\"])\n",
    "# print(nba.loc[nba[\"team_id\"] == \"MNL\", \"date_played\"].min())\n",
    "# print(nba.loc[nba[\"team_id\"] == \"MNL\", \"date_played\"].max())\n",
    "# print(nba.loc[nba[\"team_id\"] == \"MNL\", \"date_played\"].agg((\"min\", \"max\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d425a33",
   "metadata": {},
   "source": [
    "### Pandas data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45456e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding \"pandas.Series\" objects\n",
    "\n",
    "revenues = pd.Series([5555, 7000, 1980])\n",
    "print(type(revenues))\n",
    "print(revenues)\n",
    "print(\"---\")\n",
    "\n",
    "# A series object wraps two components:\n",
    "# 1. A sequence of \"values\".\n",
    "# 2. A sequence of \"identifiers\", which is the \"index\".\n",
    "print(revenues.values)\n",
    "print(type(revenues.values))\n",
    "print(revenues.index)\n",
    "print(\"---\")\n",
    "# a Pandas Series has an integer index that’s implicitly defined. \n",
    "# This implicit index indicates the element’s position in the Series.\n",
    "# However, a Series can also have an arbitrary type of index. \n",
    "# You can think of this explicit index as labels for a specific row.\n",
    "\n",
    "city_revenues = pd.Series([4200, 8000, 6500], index=[\"Amsterdam\", \"Toronto\", \"Tokyo\"])\n",
    "print(city_revenues)\n",
    "print(city_revenues.keys()) # prints indices.\n",
    "print(\"Tokyo\" in city_revenues)\n",
    "print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00cc357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding \"pandas.DataFrame\" objects\n",
    "\n",
    "# DataFrame = This data structure is a sequence of Series objects\n",
    "# that share the same index.\n",
    "\n",
    "city_revenues = pd.Series([4200, 8000, 6500], index=[\"Amsterdam\", \"Toronto\", \"Tokyo\"])\n",
    "city_employee_count = pd.Series({\"Amsterdam\": 5, \"Tokyo\": 8}) # keys acts as index.\n",
    "\n",
    "city_data = pd.DataFrame({\n",
    "    \"revenue\": city_revenues,\n",
    "    \"employee_count\": city_employee_count\n",
    "})\n",
    "\n",
    "print(city_data)\n",
    "print(city_data.index) # The new DataFrame index is the union of the two Series indices.\n",
    "print(city_data.values) # numpy ndarray\n",
    "print(\"---\")\n",
    "\n",
    "# The two dimensions of a DataFrame are also called as \"axes\".\n",
    "print(city_data.axes)\n",
    "print(city_data.axes[0]) # 0 is for row index\n",
    "print(city_data.axes[1]) # 1 is for column index\n",
    "print(\"---\")\n",
    "\n",
    "# df has also support .keys() and \"in\" keyword.\n",
    "print(city_data.keys()) # prints columns name\n",
    "print(\"Amsterdam\" in city_data) # False as \"Amsterdam\" is not a column name\n",
    "print(\"revenue\" in city_data) # True  as \"revenue\" is a column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3766a83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing Series elements\n",
    "\n",
    "# Series has two indices:\n",
    "# 1. A positional or implict index, which os always a RangeIndex\n",
    "# 2. A label or explicit index, which can contain any hashable objects\n",
    "\n",
    "city_revenues = pd.Series([4200, 8000, 6500], index=[\"Amsterdam\", \"Toronto\", \"Tokyo\"])\n",
    "\n",
    "# we can conveniently access the values in a Series with both,\n",
    "# the label and positional indices\n",
    "print(city_revenues[\"Toronto\"])\n",
    "print(city_revenues[1])\n",
    "print(\"---\")\n",
    "\n",
    "# we can also use negative indices and slices.\n",
    "print(city_revenues[-1])\n",
    "print(city_revenues[1:])\n",
    "print(city_revenues[\"Toronto\":])\n",
    "print(\"---\")\n",
    "\n",
    "# using .loc and .iloc\n",
    "# The indexing operator ([]) is convenient, but there’s a caveat. \n",
    "# What if the labels are also numbers? \n",
    "\n",
    "colors = pd.Series(\n",
    "    [\"red\", \"purple\", \"blue\", \"green\", \"yellow\"],\n",
    "    index = [1, 2, 3, 5, 8]\n",
    ")\n",
    "\n",
    "\n",
    "# For a positional index, colors[1] is \"purple\". \n",
    "# However, if you go by the label index, then colors[1] is referring to \"red\".\n",
    "\n",
    "# To avoid confusion, the Pandas Python library provides two \"data access methods\":\n",
    "# .loc refers to the \"label index\".\n",
    "# .iloc refers to the \"positional index\".\n",
    "print(colors)\n",
    "print(colors.loc[1])\n",
    "print(colors.iloc[1])\n",
    "print(\"---\")\n",
    "\n",
    "# .loc and .iloc also support the features you would expect from indexing operators, like slicing.\n",
    "# However, these data access methods have an important difference. \n",
    "# While .iloc excludes the closing element, .loc includes it.\n",
    "\n",
    "print(colors.iloc[1:3]) # Return the elements with the implicit index: 1, 2\n",
    "print(colors.loc[3:8]) # Return the elements with the explicit index between 3 and 8\n",
    "print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bf4561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing DataFrame elements\n",
    "\n",
    "# Since a DataFrame consists of Series objects, \n",
    "# we can use the very same tools to access its \n",
    "# elements.\n",
    "\n",
    "# The crucial difference is the additional \n",
    "# \"dimension\" of the DataFrame.\n",
    "\n",
    "# We can use the indexing operator for the columns \n",
    "# and the access methods .loc and .iloc on the rows.\n",
    "\n",
    "city_revenues = pd.Series([4200, 8000, 6500], index=[\"Amsterdam\", \"Toronto\", \"Tokyo\"])\n",
    "city_employee_count = pd.Series({\"Amsterdam\": 5, \"Tokyo\": 8}) # keys acts as index.\n",
    "\n",
    "city_data = pd.DataFrame({\n",
    "    \"revenue\": city_revenues,\n",
    "    \"employee_count\": city_employee_count\n",
    "})\n",
    "\n",
    "print(city_data)\n",
    "print(\"---\")\n",
    "\n",
    "# access column of df using indexing operator\n",
    "print(city_data[\"revenue\"]) #  select column named \"revenue\".\n",
    "print(type(city_data[\"revenue\"]))\n",
    "print(city_data.revenue)\n",
    "print(\"---\")\n",
    "\n",
    "# using .loc and .iloc\n",
    "print(type(city_data.loc[\"Amsterdam\"]))\n",
    "print(city_data.loc[\"Amsterdam\"])\n",
    "\n",
    "print(type(city_data.loc[\"Tokyo\": \"Toronto\"]))\n",
    "print(city_data.loc[\"Tokyo\": \"Toronto\"])\n",
    "\n",
    "print(city_data.iloc[1])\n",
    "print(city_data.iloc[-1])\n",
    "print(\"---\")\n",
    "\n",
    "\n",
    "# For a DataFrame, the data access methods .loc and .iloc also accept a second parameter. \n",
    "# While the first parameter selects rows based on the indices, \n",
    "# the second parameter selects the columns. \n",
    "# You can use these parameters together to select a subset \n",
    "# of rows and columns from your DataFrame:\n",
    "\n",
    "print(city_data.loc[\"Amsterdam\": \"Tokyo\", \"revenue\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60542eb5",
   "metadata": {},
   "source": [
    "### Querying dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcdab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter rows based on the column values\n",
    "current_decade = nba[nba[\"year_id\"] > 2010]\n",
    "print(current_decade.shape)\n",
    "print(\"---\")\n",
    "\n",
    "# select rows where specific field is not null\n",
    "games_with_notes = nba[nba[\"notes\"].notnull()] # or nba[nba[\"notes\"].notna()]\n",
    "print(games_with_notes.shape)\n",
    "print(\"---\")\n",
    "\n",
    "# access values of the object data type as str and perform\n",
    "# string operations on them\n",
    "ers = nba[nba[\"fran_id\"].str.endswith(\"ers\")]\n",
    "print(ers.shape)\n",
    "print(\"---\")\n",
    "\n",
    "# filter using multiple conditions\n",
    "nba[\n",
    "    (nba[\"_iscopy\"] == 0) &\n",
    "    (nba[\"pts\"] > 100) &\n",
    "    (nba[\"opp_pts\"] > 100) &\n",
    "    (nba[\"team_id\"] == \"BLB\")\n",
    "].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482bbf30",
   "metadata": {},
   "source": [
    "### Grouping and Aggregating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0ff5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_revenues = pd.Series([4200, 8000, 6500], index=[\"Amsterdam\", \"Toronto\", \"Tokyo\"])\n",
    "city_employee_count = pd.Series({\"Amsterdam\": 5, \"Tokyo\": 8}) # keys acts as index.\n",
    "\n",
    "city_data = pd.DataFrame({\n",
    "    \"revenue\": city_revenues,\n",
    "    \"employee_count\": city_employee_count\n",
    "})\n",
    "\n",
    "# aggregation on Series object\n",
    "print(city_revenues.sum())\n",
    "print(city_revenues.max())\n",
    "print(city_revenues.min())\n",
    "print(city_revenues.mean())\n",
    "print(\"---\")\n",
    "\n",
    "points = nba[\"pts\"]\n",
    "print(type(points))\n",
    "print(points.sum())\n",
    "print(\"---\")\n",
    "\n",
    "# groupby operations on a dataframe\n",
    "print(nba.groupby(\"fran_id\", sort=False)[\"pts\"].sum())\n",
    "print(\"---\")\n",
    "print(nba[\n",
    "    (nba[\"fran_id\"] == \"Spurs\") &\n",
    "    (nba[\"year_id\"] > 2010)\n",
    "].groupby([\"year_id\", \"game_result\"])[\"game_id\"].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a683e59f",
   "metadata": {},
   "source": [
    "### Manipulating columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9483b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = nba.copy()\n",
    "print(df.shape)\n",
    "print(\"---\")\n",
    "\n",
    "# define new column based on existing ones\n",
    "df[\"difference\"] = df.pts - df.opp_pts\n",
    "print(df[\"difference\"].max())\n",
    "print(\"---\")\n",
    "\n",
    "# rename columns\n",
    "renamed_df = df.rename(\n",
    "    columns={\n",
    "        \"game_result\": \"result\", \n",
    "        \"game_location\": \"location\"\n",
    "    }\n",
    ")\n",
    "print(renamed_df.info())\n",
    "print(\"---\")\n",
    "\n",
    "# drop columns\n",
    "elo_columns = [\"elo_i\", \"elo_n\", \"opp_elo_i\", \"opp_elo_n\"]\n",
    "df.drop(elo_columns, inplace=True, axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbf99bd",
   "metadata": {},
   "source": [
    "### Specifying Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159108df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())\n",
    "print(\"---\")\n",
    "\n",
    "# convert date_game data type to datetime object\n",
    "df[\"date_game\"] = pd.to_datetime(df[\"date_game\"])\n",
    "print(df.info())\n",
    "print(\"---\")\n",
    "\n",
    "print(df[\"game_location\"].nunique())\n",
    "print(df[\"game_location\"].value_counts())\n",
    "df[\"game_location\"] = pd.Categorical(df[\"game_location\"])\n",
    "print(df[\"game_location\"].dtype)\n",
    "print(df.info())\n",
    "print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9ac46c",
   "metadata": {},
   "source": [
    "### Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c239bea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows containing null values in any of the column\n",
    "rows_without_missing_data = nba.dropna()\n",
    "print(rows_without_missing_data.shape)\n",
    "print(\"---\")\n",
    "\n",
    "# drop columns containing null values\n",
    "data_without_missing_columns = nba.dropna(axis=1)\n",
    "print(data_without_missing_columns.shape)\n",
    "print(\"---\")\n",
    "\n",
    "# we can also replace null values with meaningful default values\n",
    "data_with_default_notes = nba.copy()\n",
    "data_with_default_notes[\"notes\"].fillna(\n",
    "    value=\"no notes at all\",\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "print(data_with_default_notes[\"notes\"].describe())\n",
    "print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79beae4",
   "metadata": {},
   "source": [
    "### Combining Multiple Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37963b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_revenues = pd.Series([4200, 8000, 6500], index=[\"Amsterdam\", \"Toronto\", \"Tokyo\"])\n",
    "city_employee_count = pd.Series({\"Amsterdam\": 5, \"Tokyo\": 8}) # keys acts as index.\n",
    "\n",
    "city_data = pd.DataFrame({\n",
    "    \"revenue\": city_revenues,\n",
    "    \"employee_count\": city_employee_count\n",
    "})\n",
    "\n",
    "further_city_data = pd.DataFrame(\n",
    "    {\"revenue\": [7000, 3400], \"employee_count\":[2, 2]},\n",
    "    index=[\"New York\", \"Barcelona\"]\n",
    ")\n",
    "\n",
    "# combine along rows\n",
    "all_city_data = pd.concat([city_data, further_city_data], sort=False, axis=0)\n",
    "print(all_city_data)\n",
    "print(\"---\")\n",
    "\n",
    "city_countries = pd.DataFrame(\n",
    "    {\n",
    "        \"country\": [\"Holland\", \"Japan\", \"Holland\", \"Canada\", \"Spain\"],\n",
    "        \"capital\": [1, 1, 0, 0, 0]\n",
    "    },\n",
    "    index=[\"Amsterdam\", \"Tokyo\", \"Rotterdam\", \"Toronto\", \"Barcelona\"]\n",
    ")\n",
    "\n",
    "# combine along columns\n",
    "cities = pd.concat([all_city_data, city_countries], axis=1, sort=False)\n",
    "print(cities)\n",
    "print(\"---\")\n",
    "\n",
    "# join operation (row index label values are considered for join operation)\n",
    "joined_df = pd.concat([all_city_data, city_countries], axis=1, join=\"inner\")\n",
    "print(joined_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python google-trends-kernel",
   "language": "python",
   "name": "google-trends-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
